Datasets
===================
FER (2013): very similar to ours 48x48 grayscale, 7 emotions
    - Page 4, human perfomance on FER-2013 was 65 +- 5%
    - https://paperswithcode.com/sota/facial-expression-recognition-on-fer2013
    - https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/code?competitionId=3364&sortBy=voteCount

FER+ (2016): extension of FER2013, 8 emotions, each image has 10 crowd-sourced taggers
    - Having a distribution of label is better since images can suggest more than 1 emotion
    - Four different losses: majority voting (single label), multi-label, probabilistic, cross-entropy
    - https://paperswithcode.com/sota/facial-expression-recognition-on-ferplus
    - https://arxiv.org/pdf/1608.01041v2.pdf

AffectNet (2017): similar to ours images, 256x256, 8 emotions, 0.4 million images along with intensity of valence and arousal
    - https://paperswithcode.com/sota/facial-expression-recognition-on-affectnet

RAF-DB (2017): 30k images, 1k+ individuals, 7 emotions, 11 compound expression with bimodal distribution
    - https://paperswithcode.com/sota/facial-expression-recognition-on-raf-db
    - https://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Reliable_Crowdsourcing_and_CVPR_2017_paper.pdf

AFEW (2011): 700 images only
CK+ (2010): 593 video sequences from 123 subjects, 7 emotions


Labels
===================
0=Angry
1=Disgust
2=Fear
3=Happy
4=Sad
5=Surprise
6=Neutral


Notes and Papers
===================
Arousal is the level of autonomic activation that an event creates, and ranges from calm (or low) to excited (or high). 
Valence is the level of pleasantness that an event generates and is defined along a continuum from negative to positive.

Look in the latest CV section of Journals for novel ideas

Augment data (Section 5.2), perturbation method:
    - https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/icmi2015_ChaZhang.pdf
Experiment with Randomized NN
    - https://arxiv.org/abs/2002.12287
Paper analysis on the state of Face Recognition (2019)
    - https://arxiv.org/pdf/1907.12739.pdf

Models
===================
Base Simple
    - https://www.kaggle.com/drcapa/facial-expression-eda-cnn
SmoothLabel representation + Finetune VGGFace 
    - https://www.kaggle.com/kilean/emotion-detection-accuracy70
ResNet + Custom
    - https://www.kaggle.com/haneenabdelmaguid/facial-expression-detection-2


Tools
===================
Image augmentation
    - https://github.com/albumentations-team/albumentations
    - https://github.com/kornia/kornia
FastAI CV models
    - https://github.com/fastai/fastai
    - Examples: https://docs.fast.ai/quick_start.html
    - Book: https://github.com/fastai/fastbook
    	- ResNet: https://github.com/fastai/fastbook/blob/master/14_resnet.ipynb

Simple Examples Full
===================
Image classification
    - https://www.pluralsight.com/guides/image-classification-with-pytorch
ResNet Transfer
    - https://www.pluralsight.com/guides/introduction-to-resnet
